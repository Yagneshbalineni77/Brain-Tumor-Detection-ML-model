import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import os

from feature_extractor import load_kaggle_brain_mri_data, extract_handcrafted_features, extract_deep_features, fuse_features, vgg_base_model, deep_feature_extractor_model

def train_and_evaluate_models(X, y):
    print("\n--- Starting Model Training and Evaluation ---")

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

    print(f"Data split: Training samples = {len(X_train)}, Testing samples = {len(X_test)}")
    print(f"Training label distribution (0: No Tumor, 1: Tumor): {np.bincount(y_train)}")
    print(f"Testing label distribution (0: No Tumor, 1: Tumor): {np.bincount(y_test)}")

    rf_clf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')
    print("\nTraining Random Forest Classifier...")
    rf_clf.fit(X_train, y_train)
    rf_pred = rf_clf.predict(X_test)
    rf_proba = rf_clf.predict_proba(X_test)[:, 1]

    svm_clf = SVC(C=1.0, kernel='rbf', probability=True, random_state=42, class_weight='balanced')
    print("Training SVM Classifier (can take some time)...")
    svm_clf.fit(X_train, y_train)
    svm_pred = svm_clf.predict(X_test)
    svm_proba = svm_clf.predict_proba(X_test)[:, 1]

    lr_clf = LogisticRegression(random_state=42, solver='liblinear', class_weight='balanced', max_iter=1000)
    print("Training Logistic Regression Classifier...")
    lr_clf.fit(X_train, y_train)
    lr_pred = lr_clf.predict(X_test)
    lr_proba = lr_clf.predict_proba(X_test)[:, 1]

    ensemble_clf = VotingClassifier(
        estimators=[('rf', rf_clf), ('svm', svm_clf), ('lr', lr_clf)],
        voting='soft', weights=[0.4, 0.3, 0.3]
    )
    print("\nTraining Hybrid Feature Fusion Ensemble (VotingClassifier)...")
    ensemble_clf.fit(X_train, y_train)
    ensemble_pred = ensemble_clf.predict(X_test)
    ensemble_proba = ensemble_clf.predict_proba(X_test)[:, 1]

    print("All models trained successfully.")

    print("\n--- Evaluating Model Performance ---")

    def evaluate_model(y_true, y_pred, y_proba, model_name):
        print(f"\n--- Metrics for {model_name} ---")
        accuracy = accuracy_score(y_true, y_pred)
        precision = precision_score(y_true, y_pred, zero_division=0)
        recall = recall_score(y_true, y_pred, zero_division=0)
        f1 = f1_score(y_true, y_pred, zero_division=0)
        roc_auc = roc_auc_score(y_true, y_proba)
        cm = confusion_matrix(y_true, y_pred)

        print(f"Accuracy: {accuracy:.4f}")
        print(f"Precision: {precision:.4f}")
        print(f"Recall (Sensitivity): {recall:.4f}")
        print(f"F1-Score: {f1:.4f}")
        print(f"AUC-ROC: {roc_auc:.4f}")
        print(f"Confusion Matrix:\n{cm}")

        plt.figure(figsize=(6, 5))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=['Predicted No Tumor', 'Predicted Tumor'],
                    yticklabels=['Actual No Tumor', 'Actual Tumor'])
        plt.title(f'Confusion Matrix for {model_name}')
        plt.ylabel('Actual Label')
        plt.xlabel('Predicted Label')
        plt.show()
        return {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1, 'roc_auc': roc_auc}

    rf_metrics = evaluate_model(y_test, rf_pred, rf_proba, "Random Forest Classifier")
    svm_metrics = evaluate_model(y_test, svm_pred, svm_proba, "SVM Classifier")
    lr_metrics = evaluate_model(y_test, lr_pred, lr_proba, "Logistic Regression Classifier")

    ensemble_metrics = evaluate_model(y_test, ensemble_pred, ensemble_proba, "Hybrid Feature Fusion Ensemble")

    print("\n--- Summary of Model Sensitivities (Recall) ---")
    print(f"Random Forest Sensitivity: {rf_metrics['recall']:.4f}")
    print(f"SVM Sensitivity: {svm_metrics['recall']:.4f}")
    print(f"Logistic Regression Sensitivity: {lr_metrics['recall']:.4f}")
    print(f"Hybrid Feature Fusion Ensemble Sensitivity: {ensemble_metrics['recall']:.4f}")

    print("\nModel training and evaluation complete.")
    print("You can now analyze the performance metrics, especially Sensitivity, for your paper.")


if __name__ == "__main__":
    print("Loading data and extracting features for model training...")

    kaggle_data_directory = os.path.join('data', 'Kaggle_Brain_MRI')

    all_images_np, all_labels_np, _ = load_kaggle_brain_mri_data(kaggle_data_directory)

    if len(all_images_np) == 0:
        print("No images loaded. Cannot proceed with model training.")
    else:
        num_samples, flat_dim = all_images_np.shape
        img_height = img_width = int(np.sqrt(flat_dim))
        all_images_reshaped = all_images_np.reshape(num_samples, img_height, img_width, 1)

        all_handcrafted_features = []
        all_deep_features = []
        all_fused_features = []

        for i, image_data in enumerate(all_images_reshaped):
            print(f"Extracting features for image {i+1}/{num_samples}...")
            handcrafted_feats = extract_handcrafted_features(image_data.squeeze())
            deep_feats = extract_deep_features(image_data)
            fused_feats = fuse_features(handcrafted_feats, deep_feats)
            all_fused_features.append(fused_feats)

        final_fused_df = pd.DataFrame(all_fused_features)
        final_fused_df.columns = final_fused_df.columns.astype(str)
        final_labels_np = np.array(all_labels_np)

        print("\nFeatures extracted and fused. Proceeding to model training...")
        train_and_evaluate_models(final_fused_df, final_labels_np)

